{
    "collab_server" : "",
    "contents" : "---\ntitle: Using Google Searches to Measure Attention to Elections\nslug: using-google-searches-to-measure-attention-to-elections\ncategories: []\ntags: []\n---\n\n<style>\nimg {\n  display: block;\n  margin: 0 auto;\n  width: 700px;\n  max-width: 100%;\n}\n\n.captioned{\n  text-align: center;\n  font-style: italic;\n}\n</style>\n\n```{r include=FALSE}\nlibrary(gtrendsR)\n\n# Functions to pull multiple samples of a query, build a list of all data,\n# extract interest over time, yield a tibble of useful data and save both to file\n\n####################################################################################\n\nstamp_string <- function(...){\n    now(tzone = \"America/Chicago\") %>%\n    str_replace_all(., \"[\\\\-\\\\:]\", \"\") %>%\n    str_replace_all(., \"[\\\\s]\", \"_\")\n}\n\n# Multiple pulls of the same query: yields timestamped list\ngtrends_loop_pull <- function(q, n=20, time, geo=c(\"US\"), s=2){\n    \n    require(tidyverse)\n    require(lubridate)\n    require(stringr)\n    library(gtrendsR)\n    \n    # Make timestamp string\n    stamp <- stamp_string()\n    \n    #Instantiate list; message: list name\n    list_name <- paste0(\"gtrends_pull_\", stamp)\n    gtrends_list <- list()\n    message(\"List name:\", list_name)\n    \n    for (i in 1:n){\n        # Pull gtrends\n        pull <- gtrends(q, geo = geo, time = time)\n        \n        # Add timestamp for the pull object\n        pull[['stamp']] <- now(tzone = \"America/Chicago\")\n        \n        # Number the pull object\n        pull_serial <- paste0(\"pull\", i)   \n        gtrends_list[[pull_serial]] <- pull\n        \n        # Message: pulling\n        message(paste0(\"Pulling \", i, \" (\", pull[['stamp']], \")\")) \n        \n        Sys.sleep(s) # So as not to get rate limited / banned\n        }\n        \n    assign(list_name, gtrends_list)\n        \n    get(list_name) # ?\n}\n\n# Yields merged table (as tibble) of interest over time\ngtrends_data_merge <- function(gtrends_list){\n    # Extract the data, name each col for the pull #, join together\n    gtrends_list %>%\n    transpose() %>%\n    .[['interest_over_time']] %>%\n    lmap(~{\n        el_name <- names(.)\n\n        names(.[[1]])[2] <- el_name\n\n        tibble(.)\n    }) %>%\n    map(~.[[1]]) %>%\n    map(~.[1:3]) %>%\n    reduce(full_join)\n}\n```\n\n```{r include=FALSE}\n# Load in google trends data after saving it earlier\n\nlibrary(lubridate)\nlibrary(stringr)\nlibrary(tidyverse)\n\ngtrends_path <- \"/Users/davidmartin/Documents/Dissertation/7_Data/Study_3/Google Trends/Data\"\n\ngtrends_04_dem <- readRDS(paste0(gtrends_path, paste0(\"gtrends_data_2004_dem\", \"_df.RDS\")))\n\ngtrends_04_rep <- readRDS(paste0(gtrends_path, paste0(\"gtrends_data_2004_repub\", \"_df.RDS\")))\n\ngtrends_08_dem <- readRDS(paste0(gtrends_path, paste0(\"gtrends_data_2008_dem\", \"_df.RDS\")))\n\ngtrends_08_rep <- readRDS(paste0(gtrends_path, paste0(\"gtrends_data_2008_repub\", \"_df.RDS\")))\n\ngtrends_party_salience <-\nlist(gtrends_04_dem,\n     gtrends_04_rep,\n     gtrends_08_dem,\n     gtrends_08_rep) %>%\nmap(select, date, pull1, keyword) %>%\nmap(~set_names(., c(\"date\", \n            paste0(str_sub(.$keyword[1], 1, 3), \"_salience\"), \"keyword\"))) %>%\nmap(~as.tibble(.[,1:2])) %>%\nreduce(full_join, by=\"date\") %>%\ntransmute(date = date,\n         dem_salience = coalesce(dem_salience.x, dem_salience.y),\n         rep_salience = coalesce(rep_salience.x, rep_salience.y))\n\nsaveRDS(gtrends_party_salience, file=paste0(gtrends_path, \"gtrends_party_salience.RDS\"))\n\ngtrends_party_salience_04 <-\ngtrends_party_salience %>%\nfilter(ymd(date) < ymd('2006-01-01'))\n\ngtrends_party_salience_08 <-\ngtrends_party_salience %>%\nfilter(ymd(date) > ymd('2006-01-01'))\n```\n\n\n```{r include=FALSE}\nlibrary(lubridate )\n\ndata_path <-'/Users/davidmartin/Documents/Dissertation/7_Data/Study_3/'\n\nprim_08_clean <- readRDS(paste0(data_path, \"primary_dates_2008_clean.RDS\"))\n\nprim_04_clean <- readRDS(paste0(data_path, \"primary_dates_2004_clean.RDS\"))\n\nlibrary(ggthemes)\nlibrary(hrbrthemes)\nlibrary(ggalt)\n```\n\n```{r include=FALSE}\n# 2008\n\n# Visualize gtrends by party over time for each year\n\nrects = tibble(start = ymd('2008-08-08'), \n                end = ymd('2008-08-24'), \n                y1 = -Inf,\n                y2 = Inf)\n\ntexts = tibble(x = c(ymd('2008-07-04'), ymd('2008-08-24'), \n                     ymd('2008-11-04'), ymd('2008-05-01'),\n                    ymd('2008-09-01'), ymd('2008-01-03'), \n                     ymd('2008-01-08'), ymd('2008-02-05')),\n                lab = c(\"July 4th\", \"Olympics\", \n                        \"General election\", \"Primaries\",\n                       \"Conventions\", \"IA\", \"NH\",\n                       \"Super Tuesday\"),\n                hjust = c(1, 1, 1, 1, 1,2,3,1),\n               vjust = c(0,-1,1, 1, 1, 0.5, 0.5, 0.5),\n               angle = c(90,90,90,0, 90, 90, 90, 90)\n              )\n\nvlines = tibble(xint = c(ymd('2008-07-04'), ymd('2008-11-04'), ymd('2008-09-01'))\n                )\nchart08 <-\nggplot() +\n#   geom_rect(data = gtrends_08_periods, \n#                  aes(xmin=ymd(grp_3wka_date_min), \n#                      xmax=ymd(grp_3wka_date_min)+20, \n#                      ymin=0, ymax=100, fill=as.character(grp_3wka)), alpha=0.1) +\n\n  geom_line(data = gtrends_party_salience_08, aes(x = ymd(date), y = dem_salience), color=4) +\n#   geom_smooth(data = gtrends_party_salience_08, aes(x = ymd(date), y = dem_salience), color=4) +\n  geom_line(data = gtrends_party_salience_08, aes(x = ymd(date), y = rep_salience), color=2) +\n#   geom_smooth(data = gtrends_party_salience_08, aes(x = ymd(date), y = rep_salience), color=2) +\n\n  geom_rect(data = rects, aes(xmin = start, xmax=end, ymin=-Inf, ymax=Inf), \n            fill=\"grey80\", alpha=0.5) +\n\n  geom_vline(data = vlines, aes(xintercept = as.numeric(xint)), color = \"grey80\", size=1.5, alpha=0.5) +\n\n  geom_vline(data = prim_08_clean, aes(xintercept = as.numeric(mdy(prim_08_clean$date))), color = \"grey60\", size=1.5, alpha=0.25) +\n\n  geom_text(data=texts, aes(x = x, y=Inf, label = lab, hjust=hjust, vjust=vjust, angle=angle), \n            size=3, alpha=0.7, color=\"black\") +\n#   geom_rect(data = elex_cycle_period_08, \n#                  aes(xmin=ymd(xmin), \n#                      xmax=ymd(xmax), \n#                      ymin=0, ymax=100, fill=label), alpha=0.3) +\n\n#   geom_errorbarh(data = elex_cycle_period_08, \n#                  aes(xmin=ymd(xmin), \n#                      xmax=ymd(xmax), \n#                      x=ymd(xmid), y=0), height=2) +\n  theme_minimal() +\n  theme(panel.background = element_rect(fill = \"white\", colour = \"grey90\")) +\n  theme_ipsum_rc(grid=\"XY\") +\n  theme(axis.text.x=element_text(hjust=c(0, 0.5, 0.5, 0.5, 0.5, 0.5)),\n       legend.title = element_blank(),\n       legend.position=\"bottom\") +\n  labs(x = \"\",\n      y=\"Google search volume\",\n      title = \"Google search volume for partisan terms\\n  across 2008 election cycle\") +\n  scale_x_date(date_labels = \"%b %Y\")\n```\n\n```{r include=FALSE}\n\n# 2004\n\n# Visualize gtrends by party over time for each year\nrects = tibble(start = ymd('2004-08-08'), \n                end = ymd('2004-08-29'),\n                y1 = -Inf,\n                y2 = Inf)\n\ntexts = tibble(x = c(ymd('2004-07-04'), ymd('2004-08-29'), \n                     ymd('2004-11-02'),ymd('2004-05-01'),\n                    ymd('2004-8-30'), ymd('2004-7-26'),\n                    ymd('2004-01-19'), ymd('2004-01-27'),\n                    ymd('2004-03-02')),\n                lab = c(\"July 4th\", \"Olympics\", \n                        \"General election\", \"Primaries\", \n                        \"R Convention\", \"D Convention\",\n                       \"IA\", \"NH\", \"Super Tuesday\"),\n                hjust = c(1, 1, 1, 1, 1,1,2,3, 1.25),\n               vjust = c(0,-1,1, 1,1,0,0,1, 0),\n               angle = c(90,90,90,0,90,90, 90, 90, 90)\n              )\n\nvlines = tibble(xint = c(ymd('2004-07-04'), ymd('2004-11-02'), \n                         ymd('2004-8-30'), ymd('2004-7-26'))\n               )\nchart04<-\nggplot() +\n  geom_line(data = gtrends_party_salience_04, aes(x = ymd(date), y = dem_salience), color=4) +\n  geom_line(data = gtrends_party_salience_04, aes(x = ymd(date), y = rep_salience), color=2) +\n  geom_rect(data = rects, aes(xmin = start, xmax=end, ymin=-Inf, ymax=Inf), \n            fill=\"grey80\", alpha=0.5) +\n\n  geom_vline(data = vlines, aes(xintercept = as.numeric(xint)), color = \"grey80\", size=1.5, alpha=0.5) +\n\n  geom_vline(data = prim_04_clean, aes(xintercept = as.numeric(mdy(prim_04_clean$date))), color = \"grey60\", size=1.5, alpha=0.25) +\n\n  geom_text(data=texts, aes(x = x, y=Inf, label = lab, hjust=hjust, vjust=vjust, angle=angle), \n            size=3, alpha=0.7, color=\"black\") +\n  theme_minimal() +\n  theme(panel.background = element_rect(fill = \"white\", colour = \"grey90\")) +\n  theme_ipsum_rc(grid=\"XY\") +\n  theme(axis.text.x=element_text(hjust=c(0, 0.5, 0.5, 0.5, 0.5, 0.5)),\n       legend.title = element_blank(),\n       legend.position=\"bottom\") +\n  labs(x = \"\",\n      y=\"Google search volume\",\n      title = \"Google search volume for partisan terms\\n  across 2004 election cycle\") +\n  scale_x_date(date_labels = \"%b %Y\")\n```\n\nFor my [dissertation project](https://github.com/dcldmartin/Dissertation_selections/), I looked into how attention to elections changes the way you think about political leaders and the government. The basic idea: the more you pay attention to partisan conflict (like an election), the more your attitudes are influenced by partisan bias. But in order to test my hypotheses statistically I needed a way to measure how attention to politics changes over time. To look at the 2004 and 2008 elections, I settled on Google search data.\n\nHere's what I like about Google searches: it doesn't tell us what the news is paying attention to, it's an actual record of what people are searching for themselves. We can expect daily newspapers and cable news channels to cover politics every day, but the average person may not. These charts show, for 2004 and 2008, the relative number of times Google users searched for Democrat/Democrats (in Blue) and Republican/Republicans (in Red). One thing to note: the scale on the y axis goes from 0 to 100, but 100 just refers to the maximum search volume recorded in a given week, for that term - not actual absolute numbers of searches. But this caveat aside, the data shows pretty much exactly what we would expect if it were measuring political attention.\n\n**Specifically:**\n\n* We can see peaks in attention around Super Tuesday, Conventions and the general election.\n* Attention is consistently low during the summer lull in the political cycle, between primaries and party conventions.\n* Attention is particularly high in Super Tuesday of 2008 when there were many more primaries concentrated on one day than in other election years.\n* The party conventions in 2004 were on different days and the search patterns reflect this.\n\n```{r echo=FALSE}\nplot(chart04)\n```\n\n```{r echo=FALSE}\nplot(chart08)\n```\n",
    "created" : 1511217807516.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1254372558",
    "id" : "4732025C",
    "lastKnownWriteTime" : 1511248450,
    "last_content_update" : 1511248450342,
    "path" : "~/Documents/Websites/portfolio/content/post/using-google-searches-to-measure-attention-to-elections.Rmd",
    "project_path" : "content/post/using-google-searches-to-measure-attention-to-elections.Rmd",
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}